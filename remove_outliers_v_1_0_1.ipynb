{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GEOS_Logo.pdf\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step **8** of **`G2FNL`**: <font color=blue>\"remove_outliers.ipynb\"</font>\n",
    "#### Nov 11, 2021  <font color=red>(v. 1.0.1)</font>\n",
    "##### Jeonghyeop Kim (jeonghyeop.kim@gmail.com)\n",
    "\n",
    "> input files: **`zeroFilled_i`**, **`days_per_month.dat`**, **`station_list_full.dat`**,  **`steps.txt`**, and **`time_vector.dat`** \\\n",
    "> output files: **`outlierRemoved_i`** : <font color=red>UNIT will be changed [m] to [mm]</font>\n",
    "\n",
    "\n",
    "0. This code is a part of GPS2FNL process \n",
    "1. It will get rid of outliers.  \n",
    "> Position data for each month will be treated as a set. \\\n",
    "> The code will fit a linear line to each month and then subtract this model from the data. \\\n",
    "> Perform a simple statistical analysis for the residual. \\\n",
    "> Outliers for each month are defined as any data outside of the tolerance level. \\\n",
    "> The default tolerance level is +/- 3 sigma. \\\n",
    "> If fewer than 6 positions are available for a month, this code will remove the data for the month.\n",
    "2. Potential issues: \n",
    "> There exist some stations that still show problematic outliers after this algorithm applied. \\\n",
    "> Possibly some post-seismic signals are identified as outliers and removed, which means a loss of interesting signal. \\\n",
    "> Maybe pass the month if an earthquake occurred in that month?\n",
    "\n",
    "3. <font color=red>** NOTE! UNIT will be changed [m] to [mm] **</font>\n",
    "4. If this algorithm identifies an outlier for a day for a component, it will remove the other two components for the day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "Do NOT run this code twice without re-starting the kernel\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3\n",
    "# outlier defined as the residual position estimates outside of the 3-sigma range for each month.\n",
    "\n",
    "turnoff_print = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jkim/main/Joint_Inversrion_GPS_INSAR/Interseismic_MintPy_SanFrancisco_10202021/GNSS_velo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir=os.getcwd()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. read files for (1) Number of Date per each month \n",
    "#               and (2) Number of Stations \n",
    "#               and (3) time_vector.dat for the first and end dates of the analysis\n",
    "#               and (4) earthquake-related steps\n",
    "\n",
    "\n",
    "#############################################\n",
    "#(1)\n",
    "datefile = 'days_per_month.dat'\n",
    "dateNvec = pd.read_csv(datefile, sep = ' ', header = None)\n",
    "dateNvec.columns = ['NofD']\n",
    "\n",
    "#############################################\n",
    "#(2)\n",
    "list_full = \"station_list_full.dat\"\n",
    "df_list=pd.read_csv(list_full, header=None)\n",
    "df_list.columns=['StID']\n",
    "N_list = len(df_list) \n",
    "\n",
    "\n",
    "#############################################\n",
    "#(3)\n",
    "timefile = 'time_vector.dat'\n",
    "df_time=pd.read_csv(timefile, header=None)\n",
    "startDateAnalysis=int(df_time.iloc[0])\n",
    "endDateAnalysis=int(df_time.iloc[-1])\n",
    "##########################################################################################\n",
    "#(4)\n",
    "metadata = \"steps.txt\" #file name\n",
    "df_metadata=pd.read_csv(metadata, header=None, names=list('0123456'), sep=r'(?:,|\\s+)', \\\n",
    "                        comment='#', engine='python')\n",
    "## steps.txt is in an irregular shape\n",
    "## 'names=list('0123456')' is to fill empty spots with NaN \n",
    "df_steps_earthquakes = df_metadata[df_metadata['2'] == 2].reset_index(drop=True)\n",
    "df_steps_earthquakes.columns=['stID','time','flag','threshold','distance','mag','eventID'] \n",
    "#The step data has a time column in the form of yyMMMdd \n",
    "date_old = df_steps_earthquakes.time.tolist() # A DataFrame to a list\n",
    "date_new = pd.to_datetime(date_old, format='%y%b%d').strftime('%Y%m%d') # convert date format\n",
    "df_steps_earthquakes.loc[:,'time'] = date_new # replaces with the new date  in YYYYMMDD\n",
    "df_steps_earthquakes['time']=df_steps_earthquakes['time'].astype(int) #str to int\n",
    "df_steps_earthquakes = df_steps_earthquakes[(df_steps_earthquakes['time']>=startDateAnalysis) & \\\n",
    "                                            (df_steps_earthquakes['time']<=endDateAnalysis)]\n",
    "df_steps_earthquakes = df_steps_earthquakes.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jkim/main/Joint_Inversrion_GPS_INSAR/Interseismic_MintPy_SanFrancisco_10202021/GNSS_velo/data/processing'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processing_dir = os.path.join(current_dir, 'data', 'processing')\n",
    "os.chdir(processing_dir) # cp to processing directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`IDENTIFY AND ELIMINATE OUTLIERS`**\n",
    "\n",
    "### FIT position data for each month with a line (LSM). \n",
    "### SUBTRACT the linear model from the data for the month. \n",
    "### DEFIND as outliers if the residuals are out of the 3 sigma range.\n",
    "### REPLACE the outliers with zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_months = len(dateNvec) # How many months for the time period of interest?\n",
    "\n",
    "##############################################\n",
    "# STEP 1: Read data files station by station #\n",
    "##############################################\n",
    "\n",
    "column_names = ['datenum','date','lon','lat','ue','un','uz','se','sn','sz','corr_en','flag']\n",
    "\n",
    "for i in range(N_list):  \n",
    "\n",
    "    inputfile = \"zeroFilled_\"+str(i+1) #input_file = zeroFilled_\"$i\"\n",
    "    df_input=pd.read_csv(inputfile,sep=' ',header=None)   \n",
    "    df_input = df_input.reset_index() #Index column will be added and will be used as 'datenum' consecutive integers.\n",
    "    df_input.columns = column_names\n",
    "    df_input.loc[:,['datenum']]=df_input.loc[:,['datenum']]+1 #datenum starts from 1 instead of 0\n",
    "    df_input.loc[:,['ue']]=df_input.loc[:,['ue']]*1000 # [m] to [mm]\n",
    "    df_input.loc[:,['un']]=df_input.loc[:,['un']]*1000 # [m] to [mm]\n",
    "    df_input.loc[:,['uz']]=df_input.loc[:,['uz']]*1000 # [m] to [mm]\n",
    "    df_input.loc[:,['se']]=df_input.loc[:,['se']]*1000 # [m] to [mm]\n",
    "    df_input.loc[:,['sn']]=df_input.loc[:,['sn']]*1000 # [m] to [mm]\n",
    "    df_input.loc[:,['sz']]=df_input.loc[:,['sz']]*1000 # [m] to [mm]\n",
    "    df_input.loc[:,['corr_en']]=df_input.loc[:,['corr_en']]*1000 # [m] to [mm]\n",
    "    stationID=df_list.loc[i,['StID']]\n",
    "    stationID=stationID.tolist()[0]\n",
    "\n",
    "##############################################\n",
    "# STEP 2: READ DATA MONTH BY MONTH!          #\n",
    "##############################################\n",
    "\n",
    "    FirstMonth = 0\n",
    "    for j in range(N_months):\n",
    "        date_for_the_month=int(dateNvec.iloc[j])\n",
    "        LastMonth = FirstMonth + date_for_the_month\n",
    "        df_month = df_input.loc[FirstMonth:LastMonth-1,:].reset_index(drop=True)\n",
    "        FirstMonth = LastMonth\n",
    "        \n",
    "        df_month_nonzero = df_month[(df_month['lon']!=0) & (df_month['lat']!=0)]\n",
    "        df_month_nonzero = df_month_nonzero.reset_index(drop=True)    \n",
    "        \n",
    "##############################################\n",
    "# STEP 3: Decide to pass the month or not    #\n",
    "##############################################\n",
    "\n",
    "        # 3-a The number of non-zero values is less than 6 : skip \n",
    "        if len(df_month_nonzero) == 0:    \n",
    "            if turnoff_print !=1:\n",
    "                print(\"few positions for the month %s for station %s : Skip this month\" %(str(f\"{j:03}\"),stationID))\n",
    "            continue\n",
    "        elif len(df_month_nonzero) > 0 and len(df_month_nonzero) < 6:\n",
    "            # HERE \n",
    "            few_data_idx = df_month_nonzero['datenum'] - 1\n",
    "            few_data_idx = few_data_idx.tolist()\n",
    "            df_input.iloc[few_data_idx,[2,3,4,5,6,7,8,9,10,11]] = 0 \n",
    "            # remove the position estimates defined as outliers  \n",
    "            if turnoff_print !=1:\n",
    "                print(\"few positions for the month %s for station %s : Skip this month\" %(str(f\"{j:03}\"),stationID))\n",
    "            continue\n",
    "            \n",
    "        # 3-b An earthquake occurred within that month : skip    \n",
    "        IniTimeNonzeroMonth=df_month_nonzero.iloc[0,1]\n",
    "        EndTimeNonzeroMonth=df_month_nonzero.iloc[-1,1]\n",
    "        df_steps_exist=df_steps_earthquakes[(df_steps_earthquakes['stID']==stationID) & \\\n",
    "                                    (df_steps_earthquakes['time']>=IniTimeNonzeroMonth) & \\\n",
    "                                    (df_steps_earthquakes['time']<=EndTimeNonzeroMonth)]    \n",
    "        \n",
    "        if len(df_steps_exist) != 0:  \n",
    "            if turnoff_print !=1:\n",
    "                print(\"Earthquake within the month %s for station %s : Skip this month\" %(str(f\"{j:03}\"),stationID))\n",
    "            continue\n",
    "            \n",
    "        # 3-c Fit the data with a line and get the residual    \n",
    "        else: \n",
    "            t = df_month_nonzero.loc[:,['datenum']]\n",
    "            ux = df_month_nonzero.loc[:,['ue']]\n",
    "            uy = df_month_nonzero.loc[:,['un']]\n",
    "            uz = df_month_nonzero.loc[:,['uz']]\n",
    "            sx = df_month_nonzero.loc[:,['se']]\n",
    "            sy = df_month_nonzero.loc[:,['sn']]\n",
    "            sz = df_month_nonzero.loc[:,['sz']]\n",
    "            \n",
    "\n",
    "            # Build G-matrix for a line\n",
    "            G_matrix = t\n",
    "            G_matrix['cont']=np.ones((len(t),1))\n",
    "            \n",
    "            # Build diagonal weighting matrice for the three components\n",
    "            sx_inv = 1/sx\n",
    "            sx_inv = sx_inv.to_numpy()  \n",
    "            wx = np.diag(sx_inv[:,0])\n",
    "            wx = pd.DataFrame(wx)\n",
    "            \n",
    "            sy_inv = 1/sy\n",
    "            sy_inv = sy_inv.to_numpy()  \n",
    "            wy = np.diag(sy_inv[:,0])\n",
    "            wy = pd.DataFrame(wy)\n",
    "            \n",
    "            sz_inv = 1/sz\n",
    "            sz_inv = sz_inv.to_numpy()  \n",
    "            wz = np.diag(sz_inv[:,0])\n",
    "            wz = pd.DataFrame(wz)\n",
    "            \n",
    "            # Wd, WG\n",
    "            x = wx @ ux\n",
    "            y = wy @ uy\n",
    "            z = wz @ uz\n",
    "            Gx = wx @ G_matrix\n",
    "            Gy = wy @ G_matrix\n",
    "            Gz = wz @ G_matrix\n",
    "            \n",
    "            \n",
    "            # Inversion (LSM)           \n",
    "            # G'\n",
    "            GxT = Gx.transpose()\n",
    "            GyT = Gy.transpose()\n",
    "            GzT = Gz.transpose()\n",
    "            # G'G\n",
    "            GpG_x=GxT @ Gx\n",
    "            GpG_y=GyT @ Gy\n",
    "            GpG_z=GzT @ Gz\n",
    "            # inv(G'G)\n",
    "            GpG_x_inv= pd.DataFrame(np.linalg.inv(GpG_x.to_numpy()), GpG_x.columns, GpG_x.index)\n",
    "            GpG_y_inv= pd.DataFrame(np.linalg.inv(GpG_y.to_numpy()), GpG_y.columns, GpG_y.index)\n",
    "            GpG_z_inv= pd.DataFrame(np.linalg.inv(GpG_z.to_numpy()), GpG_z.columns, GpG_z.index)\n",
    "            # mL2 = inv(G'G)G'd\n",
    "            model_x = GpG_x_inv @ GxT @ x\n",
    "            model_y = GpG_y_inv @ GyT @ y\n",
    "            model_z = GpG_z_inv @ GzT @ z\n",
    "            # predictions & residuals & standard deviations \n",
    "            x_pred = G_matrix @ model_x           \n",
    "            x_residual = ux - x_pred     \n",
    "            sigma_x=x_residual.std()\n",
    "            x3std=float(threshold*sigma_x)\n",
    "            \n",
    "            y_pred = G_matrix @ model_y           \n",
    "            y_residual = uy - y_pred     \n",
    "            sigma_y=y_residual.std()\n",
    "            y3std=float(threshold*sigma_y)\n",
    "            \n",
    "            z_pred = G_matrix @ model_z           \n",
    "            z_residual = uz - z_pred     \n",
    "            sigma_z=z_residual.std()\n",
    "            z3std=float(threshold*sigma_z)\n",
    "            \n",
    "            # CHECK Outliers\n",
    "            x_target=x_residual.loc[(x_residual['ue']>=x3std) | (x_residual['ue']<=-1*x3std)]\n",
    "            y_target=y_residual.loc[(y_residual['un']>=y3std) | (y_residual['un']<=-1*y3std)]\n",
    "            z_target=z_residual.loc[(z_residual['uz']>=z3std) | (z_residual['uz']<=-1*z3std)]\n",
    "            \n",
    "            # ADD monthly index numbers to the dataframe \n",
    "            x_target=x_target.reset_index() \n",
    "            x_target=x_target.loc[:,['index']]\n",
    "            y_target=y_target.reset_index()\n",
    "            y_target=y_target.loc[:,['index']]\n",
    "            z_target=z_target.reset_index()\n",
    "            z_target=z_target.loc[:,['index']]\n",
    "\n",
    "            frame = [x_target, y_target, z_target]\n",
    "            target_for_month = pd.concat(frame, ignore_index=True)\n",
    "\n",
    "\n",
    "            if len(target_for_month)>0:\n",
    "                indexOutlierMonth=target_for_month['index'].unique().tolist()\n",
    "                \n",
    "                # monthly index to entire index for outlier(s)\n",
    "                target_entire_time=df_month_nonzero.loc[indexOutlierMonth,['datenum']] - 1  \n",
    "                # datenum = index + 1; index = datenum - 1\n",
    "                \n",
    "                idx_outlier=target_entire_time['datenum'].tolist()\n",
    "                df_input.iloc[idx_outlier,[2,3,4,5,6,7,8,9,10,11]] = 0 # remove the position estimates defined as outliers\n",
    "                if turnoff_print !=1:\n",
    "                    print(\"outlier found for the month %s for station %s : Remove outliers\" %(str(f\"{j:03}\"),stationID))\n",
    "            else: \n",
    "                if turnoff_print !=1:\n",
    "                    print(\"no outlier(s) for the month %s for station %s : Skip this month\" %(str(f\"{j:03}\"),stationID))\n",
    "    \n",
    "    df_save = df_input[['datenum','date','lon','lat','ue','un','uz','se','sn','sz','corr_en','flag']]\n",
    "    df_save = df_save.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # REMOVE all data with se > 10 or sn > 10 or sz > 20\n",
    "    idx_big_error=df_save[(df_save['se']>=10) | (df_save['sn']>=10) | (df_save['sz']>=20)].index.values\n",
    "    idx_big_error=idx_big_error.tolist()\n",
    "    if len(idx_big_error)!=0:      \n",
    "        df_save.loc[idx_big_error,['lon','lat','ue','un','uz','se','sn','sz','corr_en','flag']]=0\n",
    "\n",
    "        \n",
    "    df_save_timeseries = df_save[['date','lon','lat','ue','un','uz','se','sn','sz','corr_en','flag']]\n",
    "    df_save_timeseries = df_save_timeseries.reset_index(drop=True)\n",
    "    outputfile = \"outlierRemoved_\"+str(i+1) #output_file = outlierRemoved_\"$i\"\n",
    "    df_save_timeseries.to_csv(outputfile ,header=None, index=None ,float_format='%.6f', sep=' ')\n",
    "\n",
    "    # FIT a line for the entire time span for velocity. \n",
    "    \n",
    "    df_nonzero = df_save[(df_save['lon']!=0) & (df_save['lat']!=0)]\n",
    "    df_nonzero = df_nonzero.reset_index(drop=True)  \n",
    "    \n",
    "    t = df_nonzero.loc[:,['datenum']]\n",
    "    ux = df_nonzero.loc[:,['ue']]\n",
    "    uy = df_nonzero.loc[:,['un']]\n",
    "    uz = df_nonzero.loc[:,['uz']]\n",
    "    sx = df_nonzero.loc[:,['se']]\n",
    "    sy = df_nonzero.loc[:,['sn']]\n",
    "    sz = df_nonzero.loc[:,['sz']]\n",
    "            \n",
    "\n",
    "    # Build G-matrix for a line\n",
    "    G_matrix = t\n",
    "    G_matrix['cont']=np.ones((len(t),1))\n",
    "            \n",
    "    # Build diagonal weighting matrice for the three components\n",
    "    sx_inv = 1/sx\n",
    "    sx_inv = sx_inv.to_numpy()  \n",
    "    wx = np.diag(sx_inv[:,0])\n",
    "    wx = pd.DataFrame(wx)\n",
    "            \n",
    "    sy_inv = 1/sy\n",
    "    sy_inv = sy_inv.to_numpy()  \n",
    "    wy = np.diag(sy_inv[:,0])\n",
    "    wy = pd.DataFrame(wy)\n",
    "            \n",
    "    sz_inv = 1/sz\n",
    "    sz_inv = sz_inv.to_numpy()  \n",
    "    wz = np.diag(sz_inv[:,0])\n",
    "    wz = pd.DataFrame(wz)\n",
    "            \n",
    "    # Wd, WG\n",
    "    x = wx @ ux\n",
    "    y = wy @ uy\n",
    "    z = wz @ uz\n",
    "    Gx = wx @ G_matrix\n",
    "    Gy = wy @ G_matrix\n",
    "    Gz = wz @ G_matrix\n",
    "            \n",
    "            \n",
    "    # Inversion (LSM)           \n",
    "    # G'\n",
    "    GxT = Gx.transpose()\n",
    "    GyT = Gy.transpose()\n",
    "    GzT = Gz.transpose()\n",
    "    # G'G\n",
    "    GpG_x=GxT @ Gx\n",
    "    GpG_y=GyT @ Gy\n",
    "    GpG_z=GzT @ Gz\n",
    "    # inv(G'G)\n",
    "    try:\n",
    "        GpG_x_inv= pd.DataFrame(np.linalg.inv(GpG_x.to_numpy()), GpG_x.columns, GpG_x.index)\n",
    "        GpG_y_inv= pd.DataFrame(np.linalg.inv(GpG_y.to_numpy()), GpG_y.columns, GpG_y.index)\n",
    "        GpG_z_inv= pd.DataFrame(np.linalg.inv(GpG_z.to_numpy()), GpG_z.columns, GpG_z.index)\n",
    "    except: \n",
    "        GpG_x_inv= pd.DataFrame(np.linalg.pinv(GpG_x.to_numpy()), GpG_x.columns, GpG_x.index)\n",
    "        GpG_y_inv= pd.DataFrame(np.linalg.pinv(GpG_y.to_numpy()), GpG_y.columns, GpG_y.index)\n",
    "        GpG_z_inv= pd.DataFrame(np.linalg.pinv(GpG_z.to_numpy()), GpG_z.columns, GpG_z.index)        \n",
    "    \n",
    "    # mL2 = inv(G'G)G'd\n",
    "    model_x = GpG_x_inv @ GxT @ x\n",
    "    model_y = GpG_y_inv @ GyT @ y\n",
    "    model_z = GpG_z_inv @ GzT @ z\n",
    "    \n",
    "#    vel = [model_x[0],model_y[0],model_z[0]]\n",
    "    \n",
    "    frame_model=[model_x, model_y, model_z]\n",
    "    df_model = pd.concat(frame_model, ignore_index=True, axis=1)\n",
    "    df_model.reset_index(drop=True)\n",
    "    df_model.columns=['x','y','z']\n",
    "    df_model.index=['vel (mm/day)','intercept (mm)']\n",
    "    df_model = df_model.transpose()\n",
    "    velfile = \"velocity_\"+str(i+1)\n",
    "    df_model.to_csv(velfile ,header=None, index=None ,float_format='%.6f', sep=' ')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
